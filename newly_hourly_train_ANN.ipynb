{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pyforest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_after_drops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(2108, inplace=True) #contained a null so drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Load'] = data['Load'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['Load'] == 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['Hour','Day','Temperature','Pressure','Month','Relative Humidity']]\n",
    "label = data['Load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Preprocessing and splitting into features and targets, train and test sets\n",
    "\n",
    "# #loading features into X\n",
    "# X=np.array(features)\n",
    "\n",
    "# #Storing label or targets into y\n",
    "# y=np.array(label)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.10)\n",
    "\n",
    "# #reshaping X_train\n",
    "# X_train = np.reshape(X_train,(X_train.shape[0],X_train.shape[1]))\n",
    "\n",
    "# #reshaping X_test\n",
    "# X_test = np.reshape(X_test,(X_test.shape[0],X_test.shape[1]))\n",
    "# #splitting data into X_train, X_test, y_train, y_test\n",
    "\n",
    "# #reshaping X_train\n",
    "# # X_train = np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "\n",
    "# # #reshaping X_test\n",
    "# # X_test = np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train.shape\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # y_train.shape\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization\n",
    "# label=np.reshape(label, (-1,1))\n",
    "# scaler_x = MinMaxScaler()\n",
    "# scaler_y = MinMaxScaler()\n",
    "# print(scaler_x.fit(features))\n",
    "# xscale=scaler_x.transform(features)\n",
    "# print(scaler_y.fit(label))\n",
    "# yscale=scaler_y.transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xscale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, label_train, label_test = train_test_split(features,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ghaff/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ghaff/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/home/ghaff/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/ghaff/anaconda3/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features_train_scaled = scaler.fit_transform(features_train)\n",
    "features_test_scaled = scaler.fit_transform(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.66322904,  1.22619469, -1.39189233,  0.99709771, -0.362894  ,\n",
       "         1.27818216],\n",
       "       [-1.62428798,  1.22619469, -0.05719082,  0.24934242, -1.04551999,\n",
       "         0.3676626 ],\n",
       "       [-1.19548141, -0.15577591, -1.05640678,  0.99709771,  1.45744198,\n",
       "         0.44839833],\n",
       "       ...,\n",
       "       [ 0.09093829, -1.19225387,  1.49231799,  0.08910915, -0.817978  ,\n",
       "        -0.66396054],\n",
       "       [-0.05199723, -0.50126857,  1.0627034 ,  0.46298679, -0.817978  ,\n",
       "        -1.99834265],\n",
       "       [ 0.09093829, -1.65291074,  1.0349474 ,  1.58461971, -0.590436  ,\n",
       "        -1.61933328]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 13:20:52.761285 140385475991360 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: inputs=      Hour  Day  Temperature  Pressure  Month  Relative Humidity\n2710    24   26       21.470    981.05      4              97.15\n593      1   26       27.000    979.65      1              76.85\n3768     4   14       22.860    981.05     12              78.65\n583     15   25       33.135    977.45      1              52.60\n1905    15   22       29.755    977.90      3              72.75\n...    ...  ...          ...       ...    ...                ...\n2058     1   29       27.775    980.05      3              80.55\n614     23   26       25.950    980.50      1              57.75\n838     13    5       33.420    979.35      2              53.85\n977     12   11       31.640    980.05      2              24.10\n1405    13    1       31.525    982.15      3              32.55\n\n[3142 rows x 6 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-f2a8106ed93f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[0;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m     \u001b[0;31m# structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m     \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[0;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     raise ValueError(\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: inputs=      Hour  Day  Temperature  Pressure  Month  Relative Humidity\n2710    24   26       21.470    981.05      4              97.15\n593      1   26       27.000    979.65      1              76.85\n3768     4   14       22.860    981.05     12              78.65\n583     15   25       33.135    977.45      1              52.60\n1905    15   22       29.755    977.90      3              72.75\n...    ...  ...          ...       ...    ...                ...\n2058     1   29       27.775    980.05      3              80.55\n614     23   26       25.950    980.50      1              57.75\n838     13    5       33.420    979.35      2              53.85\n977     12   11       31.640    980.05      2              24.10\n1405    13    1       31.525    982.15      3              32.55\n\n[3142 rows x 6 columns]"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "#     LSTM(25, input_shape=features_train.shape[1:]),\n",
    "    Dropout(0.1),\n",
    "    Dense(30, activation='relu'),    \n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd',metrics=['acc'])\n",
    "model.fit(features_train, label_train, epochs=100)\n",
    "model.evaluate(features_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = features_test[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2157    23.8\n",
       "7446    29.4\n",
       "7862    33.2\n",
       "Name: Load, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_test[2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1202 09:28:23.342856 140385475991360 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.77123],\n",
       "       [29.77123],\n",
       "       [29.77123]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3771 samples\n",
      "Epoch 1/1000\n",
      "3771/3771 [==============================] - 1s 230us/sample - loss: 89.8036 - mse: 89.8036 - mae: 7.9237 - accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "3771/3771 [==============================] - 0s 71us/sample - loss: 86.2330 - mse: 86.2330 - mae: 7.8008 - accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 83.6095 - mse: 83.6095 - mae: 7.7018 - accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 81.0585 - mse: 81.0585 - mae: 7.6103 - accuracy: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 81.1924 - mse: 81.1924 - mae: 7.6140 - accuracy: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 80.0293 - mse: 80.0293 - mae: 7.5631 - accuracy: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 80.0238 - mse: 80.0238 - mae: 7.5669 - accuracy: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 78.4838 - mse: 78.4838 - mae: 7.4880 - accuracy: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 79.9569 - mse: 79.9569 - mae: 7.5704 - accuracy: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 78.2700 - mse: 78.2700 - mae: 7.4985 - accuracy: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 79.3329 - mse: 79.3329 - mae: 7.5297 - accuracy: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 77.0628 - mse: 77.0628 - mae: 7.3882 - accuracy: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 76.9969 - mse: 76.9969 - mae: 7.3936 - accuracy: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 76.0721 - mse: 76.0722 - mae: 7.3638 - accuracy: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 75.9558 - mse: 75.9558 - mae: 7.3176 - accuracy: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "3771/3771 [==============================] - 0s 67us/sample - loss: 76.2787 - mse: 76.2787 - mae: 7.3401 - accuracy: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 76.0084 - mse: 76.0083 - mae: 7.3270 - accuracy: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 74.3721 - mse: 74.3721 - mae: 7.2737 - accuracy: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 73.8612 - mse: 73.8612 - mae: 7.2154 - accuracy: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 74.3102 - mse: 74.3102 - mae: 7.2044 - accuracy: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 73.0232 - mse: 73.0232 - mae: 7.1480 - accuracy: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 73.8591 - mse: 73.8591 - mae: 7.1635 - accuracy: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "3771/3771 [==============================] - 0s 67us/sample - loss: 72.2539 - mse: 72.2539 - mae: 7.1164 - accuracy: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 72.3919 - mse: 72.3919 - mae: 7.0754 - accuracy: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 72.0707 - mse: 72.0707 - mae: 7.0425 - accuracy: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 70.4258 - mse: 70.4258 - mae: 6.9482 - accuracy: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 70.8566 - mse: 70.8566 - mae: 6.9426 - accuracy: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "3771/3771 [==============================] - 0s 67us/sample - loss: 71.9786 - mse: 71.9786 - mae: 6.9935 - accuracy: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "3771/3771 [==============================] - 0s 67us/sample - loss: 68.8206 - mse: 68.8206 - mae: 6.8349 - accuracy: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "3771/3771 [==============================] - 0s 69us/sample - loss: 69.2638 - mse: 69.2638 - mae: 6.8101 - accuracy: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "3771/3771 [==============================] - 0s 68us/sample - loss: 69.1941 - mse: 69.1941 - mae: 6.7802 - accuracy: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 66.7064 - mse: 66.7064 - mae: 6.6671 - accuracy: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 66.9123 - mse: 66.9123 - mae: 6.6632 - accuracy: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 64.3298 - mse: 64.3298 - mae: 6.5188 - accuracy: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 64.0898 - mse: 64.0898 - mae: 6.4795 - accuracy: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 63.1891 - mse: 63.1891 - mae: 6.4081 - accuracy: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "3771/3771 [==============================] - 0s 71us/sample - loss: 62.7445 - mse: 62.7445 - mae: 6.3352 - accuracy: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 61.9027 - mse: 61.9027 - mae: 6.2950 - accuracy: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 60.9333 - mse: 60.9333 - mae: 6.2212 - accuracy: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 60.3803 - mse: 60.3803 - mae: 6.1643 - accuracy: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 59.0282 - mse: 59.0282 - mae: 6.0575 - accuracy: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 59.2668 - mse: 59.2668 - mae: 6.0547 - accuracy: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 58.7645 - mse: 58.7645 - mae: 5.9886 - accuracy: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 58.0516 - mse: 58.0516 - mae: 5.9289 - accuracy: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 57.0972 - mse: 57.0972 - mae: 5.8509 - accuracy: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 57.0888 - mse: 57.0888 - mae: 5.8625 - accuracy: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 57.7373 - mse: 57.7373 - mae: 5.8605 - accuracy: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 58.3254 - mse: 58.3254 - mae: 5.8777 - accuracy: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "3771/3771 [==============================] - 0s 58us/sample - loss: 57.4979 - mse: 57.4979 - mae: 5.8332 - accuracy: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 56.5182 - mse: 56.5183 - mae: 5.7565 - accuracy: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 57.2978 - mse: 57.2979 - mae: 5.7929 - accuracy: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.2954 - mse: 56.2954 - mae: 5.7367 - accuracy: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 56.6293 - mse: 56.6293 - mae: 5.7747 - accuracy: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 56.9139 - mse: 56.9139 - mae: 5.7518 - accuracy: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 56.5622 - mse: 56.5623 - mae: 5.7314 - accuracy: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 56.1216 - mse: 56.1217 - mae: 5.7055 - accuracy: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.3358 - mse: 56.3358 - mae: 5.7071 - accuracy: 0.0000e+00\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3771/3771 [==============================] - 0s 59us/sample - loss: 56.7093 - mse: 56.7093 - mae: 5.7434 - accuracy: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.9520 - mse: 56.9520 - mae: 5.7360 - accuracy: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.5055 - mse: 56.5055 - mae: 5.7017 - accuracy: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 57.0059 - mse: 57.0059 - mae: 5.7539 - accuracy: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 56.3364 - mse: 56.3364 - mae: 5.6606 - accuracy: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.0536 - mse: 56.0536 - mae: 5.6664 - accuracy: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.8039 - mse: 55.8039 - mae: 5.6433 - accuracy: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 55.9109 - mse: 55.9109 - mae: 5.6761 - accuracy: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 55.4487 - mse: 55.4487 - mae: 5.6085 - accuracy: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 56.8557 - mse: 56.8557 - mae: 5.7115 - accuracy: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 56.7779 - mse: 56.7779 - mae: 5.7018 - accuracy: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 55.9441 - mse: 55.9441 - mae: 5.6776 - accuracy: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 56.3879 - mse: 56.3879 - mae: 5.6840 - accuracy: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.8395 - mse: 54.8395 - mae: 5.5969 - accuracy: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 55.5885 - mse: 55.5885 - mae: 5.6161 - accuracy: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 56.6816 - mse: 56.6816 - mae: 5.6942 - accuracy: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 55.7712 - mse: 55.7712 - mae: 5.6399 - accuracy: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "3771/3771 [==============================] - 0s 58us/sample - loss: 55.5713 - mse: 55.5714 - mae: 5.6399 - accuracy: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 55.0250 - mse: 55.0250 - mae: 5.5827 - accuracy: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 56.6967 - mse: 56.6967 - mae: 5.7269 - accuracy: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.3291 - mse: 55.3291 - mae: 5.6328 - accuracy: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 55.8610 - mse: 55.8610 - mae: 5.6321 - accuracy: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.7678 - mse: 55.7678 - mae: 5.6634 - accuracy: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.7965 - mse: 54.7965 - mae: 5.5852 - accuracy: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 56.5694 - mse: 56.5694 - mae: 5.6730 - accuracy: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 57.1934 - mse: 57.1934 - mae: 5.7044 - accuracy: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "3771/3771 [==============================] - 0s 58us/sample - loss: 54.9616 - mse: 54.9616 - mae: 5.5946 - accuracy: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "3771/3771 [==============================] - 0s 58us/sample - loss: 54.9970 - mse: 54.9970 - mae: 5.5775 - accuracy: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 55.3370 - mse: 55.3370 - mae: 5.5901 - accuracy: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 55.4398 - mse: 55.4398 - mae: 5.6046 - accuracy: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.8018 - mse: 55.8018 - mae: 5.6275 - accuracy: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 56.7205 - mse: 56.7205 - mae: 5.6940 - accuracy: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 55.4729 - mse: 55.4728 - mae: 5.6282 - accuracy: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "3771/3771 [==============================] - 0s 57us/sample - loss: 55.4089 - mse: 55.4089 - mae: 5.6176 - accuracy: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 55.0621 - mse: 55.0621 - mae: 5.5960 - accuracy: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.7923 - mse: 55.7923 - mae: 5.6220 - accuracy: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 55.6609 - mse: 55.6609 - mae: 5.6349 - accuracy: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "3771/3771 [==============================] - 0s 59us/sample - loss: 55.1509 - mse: 55.1509 - mae: 5.6002 - accuracy: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.0396 - mse: 55.0396 - mae: 5.5838 - accuracy: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 56.3712 - mse: 56.3713 - mae: 5.7049 - accuracy: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.4106 - mse: 54.4106 - mae: 5.5407 - accuracy: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 55.0743 - mse: 55.0743 - mae: 5.5859 - accuracy: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 55.4086 - mse: 55.4086 - mae: 5.6211 - accuracy: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "3771/3771 [==============================] - 0s 57us/sample - loss: 55.2829 - mse: 55.2829 - mae: 5.6138 - accuracy: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "3771/3771 [==============================] - 0s 59us/sample - loss: 54.8608 - mse: 54.8609 - mae: 5.5695 - accuracy: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 54.9064 - mse: 54.9064 - mae: 5.5789 - accuracy: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 55.0500 - mse: 55.0500 - mae: 5.6077 - accuracy: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "3771/3771 [==============================] - 0s 59us/sample - loss: 56.7571 - mse: 56.7571 - mae: 5.7049 - accuracy: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 54.7506 - mse: 54.7506 - mae: 5.5907 - accuracy: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 54.6966 - mse: 54.6966 - mae: 5.5806 - accuracy: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.7144 - mse: 54.7144 - mae: 5.5906 - accuracy: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 54.9367 - mse: 54.9367 - mae: 5.5700 - accuracy: 0.0000e+00\n",
      "Epoch 110/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.3076 - mse: 54.3076 - mae: 5.5601 - accuracy: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 54.5985 - mse: 54.5985 - mae: 5.5792 - accuracy: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "3771/3771 [==============================] - 0s 59us/sample - loss: 54.1153 - mse: 54.1153 - mae: 5.5550 - accuracy: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 55.1550 - mse: 55.1550 - mae: 5.5945 - accuracy: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "3771/3771 [==============================] - 0s 73us/sample - loss: 54.4374 - mse: 54.4374 - mae: 5.5470 - accuracy: 0.0000e+00\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3771/3771 [==============================] - 0s 65us/sample - loss: 55.6304 - mse: 55.6304 - mae: 5.6189 - accuracy: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 54.5308 - mse: 54.5308 - mae: 5.5795 - accuracy: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "3771/3771 [==============================] - 0s 70us/sample - loss: 54.5312 - mse: 54.5312 - mae: 5.5563 - accuracy: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 54.3264 - mse: 54.3264 - mae: 5.5477 - accuracy: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 54.8564 - mse: 54.8564 - mae: 5.5954 - accuracy: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 53.8376 - mse: 53.8376 - mae: 5.5120 - accuracy: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 54.0688 - mse: 54.0688 - mae: 5.5263 - accuracy: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.8803 - mse: 54.8803 - mae: 5.6031 - accuracy: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 54.2553 - mse: 54.2553 - mae: 5.5499 - accuracy: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "3771/3771 [==============================] - 0s 65us/sample - loss: 54.2445 - mse: 54.2445 - mae: 5.5449 - accuracy: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.1833 - mse: 55.1833 - mae: 5.6055 - accuracy: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 53.8682 - mse: 53.8683 - mae: 5.5119 - accuracy: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 55.1888 - mse: 55.1888 - mae: 5.5823 - accuracy: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 54.4668 - mse: 54.4668 - mae: 5.5648 - accuracy: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 54.3359 - mse: 54.3359 - mae: 5.5669 - accuracy: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 54.0112 - mse: 54.0112 - mae: 5.5262 - accuracy: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "3771/3771 [==============================] - 0s 64us/sample - loss: 53.8125 - mse: 53.8125 - mae: 5.5029 - accuracy: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 54.4452 - mse: 54.4452 - mae: 5.5805 - accuracy: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "3771/3771 [==============================] - 0s 63us/sample - loss: 54.4216 - mse: 54.4216 - mae: 5.5613 - accuracy: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "3771/3771 [==============================] - 0s 60us/sample - loss: 54.4100 - mse: 54.4100 - mae: 5.5671 - accuracy: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "3771/3771 [==============================] - 0s 62us/sample - loss: 53.7817 - mse: 53.7817 - mae: 5.4885 - accuracy: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "3771/3771 [==============================] - 0s 61us/sample - loss: 54.2732 - mse: 54.2732 - mae: 5.5274 - accuracy: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "3771/3771 [==============================] - 0s 66us/sample - loss: 54.0561 - mse: 54.0561 - mae: 5.5285 - accuracy: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "2432/3771 [==================>...........] - ETA: 0s - loss: 55.0116 - mse: 55.0116 - mae: 5.5995 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e781fa656f1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
